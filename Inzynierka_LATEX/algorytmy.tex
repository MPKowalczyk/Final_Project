\chapter{Algorytmy}
\label{cha:algorytmy}

W rozdziale tym omówione zostaną algorytmy śledzenia. Rozważymy również możliwość oraz skuteczność ich implementacji sprzętowej i sprzętowo-programowej.

\section{Śledzenie przez detekcję}
\label{sec:sledzenieprzezdetekcje}

Jest to najłatwiejszy możliwy algorytm śledzenia. Polega on na detekcji obiektu i określeniu jego położenia (np. poprzez wyznaczenie środka ciężkości). Algorytm ten jest efektywny tylko, gdy w kadrze znajduje się maksymalnie jeden wyznaczony obiekt. Ograniczenie to możemy obejść przez zastosowanie dodatkowo algorytmu indeksacji. Wtedy musimy zdecydować który z wyznaczonych obiektów jest tym właściwym. Możemy np. śledzić element znajdujący się najbliżej (mający największą powierzchnię w kadrze). Efektywność implementacji programowo-sprzętowej zależy w większości od wykorzystanego algorytmu detekcji, i/lub segmentacji. Algorytm detekcji na podstawie koloru będzie łatwy i szybki do zaimplementowania, a algorytm bazujący na współczynnikach kształtu  wymagać będzie dużo więcej pracy i zasobów.

\section{Mean-shift}
\label{sec:meanshift}

Algorytm ten bazuje na statystycznej metodzie poszukiwania lokalnego maksimum rozkładu prawdopodobieństwa. Polega on na wyznaczeniu maksymalnej wartości prawdopodobieństwa w aktualnym oknie wokół punktu startowego. W celu zastosowania tego algorytmu do śledzenia obiektu należy przedstawić obraz jako rozkład prawdopodobieństwa. W tym celu każdemu pikselowi przypisuje się wartość prawdopodobieństwa. Można to zrobić np. na podstawie koloru, przypisując kolorom wartość prawdopodobieństwa, lub histogramu, porównując histogram otoczenia piksela z histogramem obiektu \cite{CMS}. Jeśli prawdopodobieństwo obliczone zostaje tylko na podstawie koloru, dobre wyniki można uzyskać, gdy \cite{CMS}:
\begin{itemize}
\item Obiekt ma jednolitą barwę.
\item Występują bardzo małe zmiany oświetlenia.
\item W kadrze nie ma obiektów podobnych do śledzonego.
\item Kolor tła znacznie różni się od koloru obiektu.
\item Obiekt nie zostaje całkowicie zasłonięty.
\end{itemize}
\paragraph*{}
Algorytm ten ma następujący przebieg:
\begin{enumerate}
\item Wybierz rozmiar okna.
\item Wybierz początkowe położenie(środek) okna.
\item Wyznacz położenie maksimum wartości prawdopodobieństwa w oknie.
\item Przesuń okno, aby wyznaczone maksimum było jego środkiem.
\item Powtarzaj kroki 3 i 4, aż algorytm będzie zbieżny.
\end{enumerate}
\paragraph*{}
Punktem startowym dla każdego kolejnego obrazu z kamery jest pozycja obiektu w poprzednim obrazie. Poszukiwanie maksymalnej wartości prawdopodobieństwa odbywa się w następujący sposób:
\begin{itemize}
\item Obliczamy moment zerowy.
\begin{equation}
M_{00}=\sum\limits_{x}\sum\limits_{y}l(x,y)
\end{equation}
\item Obliczamy moment pierwszy dla osi poziomej.
\begin{equation}
M_{10}=\sum\limits_{x}\sum\limits_{y}x \cdot l(x,y)
\end{equation}
\item Obliczamy moment pierwszy dla osi pionowej.
\begin{equation}
M_{01}=\sum\limits_{x}\sum\limits_{y}y \cdot l(x,y)
\end{equation}
\item Obliczamy środek rozkładu prawdopodobieństwa w danym oknie.
\begin{equation}
x_c=\frac{M_{10}}{M_{00}}
\end{equation}
\begin{equation}
y_c=\frac{M_{01}}{M_{00}}
\end{equation}
\end{itemize}
Gdzie \(l(x,y)\) jest wartością prawdopodobieństwa dla piksela \((x,y)\)\cite{BCV}.

%\paragraph*{}
%Można wykorzystać przykładowe jądra:
%\begin{itemize}
%\item Płaskie
%\[K(x)=\begin{cases}1 & \text{dla } x \leqslant R \\ 0 & \text{dla } x>R \end{cases}\]
%\item Gaussowskie
%\[K(x)=\frac{1}{2\pi}\mathrm{e}^{-\frac{1}{2} \cdot |x|^2}\]
%\end{itemize}
%\paragraph*{}
%Dla zestawu \(n\) punktów w 2-wymiarowej przestrzeni estymacja gęstości jądra z jądrem K(x) i promieniem %#\(h\) wynosi:
%#\[f_K(x)=\frac{1}{nh^2} \cdot \sum\limits_{i=1}^{n}K(\frac{x-x_i}{h})\]

\section{Filtr cząsteczkowy}
\label{sec:filtrczasteczkowy}

Filtr cząsteczkowy inaczej nazywany jest sekwencyjną metodą Monte Carlo. Punktem startowym algorytmów tego typu jest model obiektu w postaci równań stanu \cite{Mukhtar}:
\begin{equation}
\label{eq:PF_state}
x_k=Ax_{k-1}+Bu_k+w_{k-1}
\end{equation}
\begin{equation}
y_k=Cx_k+v_k
\end{equation}
\(x_k\) jest ukrytym, prawdziwym stanem obiektu.\newline
\(y_k\) jest obserwowanym stanem obiektu.\newline
\(w_{k-1}\) jest zmienną losową o rozkładzie normalnym reprezentującą szum przetwarzania.\newline
\(v_k\) jest zmienną losową o rozkładzie normalnym reprezentującą szum pomiarowy.\newline
%Jeśli obiekt porusza się ze stałą prędkością, przyjąć należy następujące macierze \(A\) i \(B\):
%\begin{equation}
%A=2 \cdot I
%\end{equation}
%\begin{equation}
%B=-I
%\end{equation}

\paragraph*{}
Algorytm korzysta z wyprowadzonej z twierdzenia Bayesa rekurencyjnej zależności:
\begin{equation}
p(x_{k+1}|y_{0:k+1}) \propto p(y_{k+1}|x_{k+1}) \int\limits_{x_k} p(x_{k+1}|x_k)p(x_k|y_{0:k})dx_k
\end{equation}
\(x_{0:k}\) oznacza wektor \((x_0,\dots,x_k)\).
Powyższy wzór opisuje rozkład prawdopodobieństwa, zmiennej \(x_{k+1}\), pod warunkiem, że znane są dotychczasowe pomiary \(y_{0:k+1}\). Wartość oczekiwana tego rozkład przyjmowana jest jako wynik zadania śledzenia. W opisywanym algorytmie równanie to rozwiązywane jest metodą Monte Carlo, która skomplikowane problemy przybliża za pomocą zbioru losowo rozmieszczonych cząstek. W omawianym przypadku przybliżaną wielkością jest prawdopodobieństwo \(p(x_{k+1}|y_{0:k+1})\). Cząsteczki reprezentują możliwe położenia śledzonego obiektu \cite{Meresinski}.

\paragraph*{}
Następnie należy każdej cząsteczce przypisać wagę, która reprezentuje prawdopodobieństwo \(p(y_{k+1}|x_{k+1})\). Może być określona np. w następujący sposób \cite{Meresinski}:
\begin{equation}
w_i=ke^{-\Lambda D^2}
\end{equation}
\(k\) jest stałą normalizującą sumę wag.
\(\Lambda\) jest parametrem algorytmu.
\(D\) jest dystansem.

Najczęściej stosownym dystansem jest podobieństwo histogramu cząsteczki z histogramem bazowym obiektu. Pozycja obiektu wyznaczana jest następująco:
\begin{equation}
\label{eq:PF_polozenie}
x_{k+1}=\sum\limits_{i=1}^{M} w_{i,k+1} \cdot x_{i,k+1}
\end{equation}

Ostatnim etapem jest powielenie cząstek. Losowanych jest M cząstek z prawdopodobieństwem określonym przez wyliczone wagi (cząstka może być wylosowana więcej niż jeden raz). Następnie są one rozrzucane zgodnie z równaniem \ref{eq:PF_state}. Jest to etap predykcji. W wyniku tego działania większość cząstek znowu znajduje się w otoczeniu śledzonego obiektu.

\paragraph*{}
Algorytm ma następujący przebieg \cite{Meresinski}:
\begin{enumerate}
\item Wyznaczenie histogramu śledzonego obiektu.
\item Rozmieszczenie cząstek wokół początkowego położenia obiektu zgodnie z wybranym rozkładem (najczęściej normalnym).
\item Etap przewidywania. Przesunięcie cząstek zgodnie z równaniami stanu \ref{eq:PF_state}.
\item Obliczenie histogramu w otoczeniu każdej cząstki.
\item Obliczenie wagi każdej cząstki.
\item Obliczenie najbardziej prawdopodobnego położenia obiektu zgodnie z równaniem \ref{eq:PF_polozenie}.
\item Powielenie cząstek.
\end{enumerate}

\section{KLT}
\label{sec:klt}
Algorytm opisany przez Kanade'a, Lucas'a i Tomasi'a może posłużyć do śledzenie obiektu na obrazie w skali szarości. Polega on na poszukiwaniu najlepszego dopasowania obrazu referencyjnego \(T(x)\) do aktualnej ramki otrzymanej z kamery \(I(x)\) \cite{TSK}. Obrazy te są przesuwane względem siebie o wektor \(p\):
\begin{equation}
W(x,p)=
	\begin{bmatrix}
	x_1+p_1 \\
	x_2+p_2
	\end{bmatrix}
\end{equation}
Poszukiwane jest więc minimum następującej funkcji:
\begin{equation}
f(x,p)=\sum\limits_{x}((I(W(x,p))-T(x))^2
\end{equation}
Zakłada się, że początkowa wartość przesunięcia \(p\) jest znana, a poszukiwana jest najlepsza modyfikacja tego przesunięcia \(\Delta p\).
\begin{equation}
f(x,\Delta p)=\sum\limits_{x}((I(W(x,p+\Delta p))-T(x))^2
\end{equation}
Po znalezieniu optymalnego przesunięcia \(\Delta p\) aktualizowana jest wartość przesunięcia początkowego:
\begin{equation}
p \leftarrow p+\Delta p
\end{equation}
\paragraph*{}
Funkcja \(I(x,p+\Delta p)\) linearyzowana jest w otoczeniu punktu \((x,p)\) ze względu na \(\Delta p\) poprzez rozwinięcie w szereg Taylora pierwszego rzędu.
\begin{equation}
f(x,\Delta p)=\sum\limits_{x}(I(W(x,p))+\nabla I \cdot \frac{\partial W}{\partial p} \cdot \Delta p-T(x))^2
\end{equation}
\(\nabla I=[\frac{\partial I}{\partial x_1}, \frac{\partial I}{\partial x_2}]\) jest transponowanym gradientem obrazu wejściowego w punkcie \(W(x,p)\).\\*
\(\frac{\partial W}{\partial p}\) jest Jakobianem przesunięcia obrazów.
\paragraph*{}
Obliczamy pochodną funkcji dopasowania \(f(x,\Delta p)\) po \(\Delta p\) i przyrównujemy ją do zera.
\begin{equation}
\frac{\partial f(x,\Delta p)}{\partial \Delta p}=2 \cdot \sum\limits_{x} (\nabla I \cdot \frac{\partial W}{\partial p})^T \cdot ((I(W(x,p))+\nabla I \cdot \frac{\partial W}{\partial p} \cdot \Delta p-T(x))=0
\end{equation}
\paragraph*{}
Przekształcając powyższy wzór otrzymuje się:
\begin{equation}
\Delta p=H^{-1} \cdot \sum\limits_{x}(\nabla I \cdot \frac{\partial W}{\partial p})^T \cdot (T(x)-I(W(x,p)))
\end{equation}
\(H\) jest Hesjanem:
\begin{equation}
H=\sum\limits_{x}(\nabla I \cdot \frac{\partial W}{\partial p})^T \cdot (\nabla I \cdot \frac{\partial W}{\partial p})
\end{equation}
\paragraph*{}
Aby algorytm dobrze działał musimy odpowiednio wybrać obraz referencyjny. Zauważmy, że we wzorze na \(\Delta p\) jest odwrotność Hesjanu. Odwracanie macierzy może powodować duże błędy numeryczne, gdy macierz ta jest źle uwarunkowana. Oznacza to, że Hesjan musi posiadać odpowiednio duże wartości własne.
\begin{equation}
\lambda(H)>\lambda_{thr}
\end{equation}
\paragraph*{}
W praktyce powyższy warunek oznacza, że obraz referencyjny nie może być jednolity. W najlepszym wypadku zawierał będzie on krawędzie śledzonego obiektu.
\paragraph*{}
Algorytm ma następujący przebieg \cite{KK}:
\begin{enumerate}
\item Znajdź obszary spełniające warunek na wartości własne hesjanu.
\item Wyznacz obraz przesunięty o \(p\).
\item Wyznacz gradient \(\nabla I\).
\item Oblicz Jakobian \(\frac{\partial W}{\partial p}\) oraz iloczyn \(\nabla I \cdot \frac{\partial W}{\partial p}\).
\item Oblicz Hesjan \(H=\sum\limits_x (\nabla I \cdot \frac{\partial W}{\partial p})^T \cdot (\nabla I \cdot \frac{\partial W}{\partial p})\).
\item Wyznacz przesunięcie \(\Delta p=H^{-1} \cdot \sum\limits_x (\nabla I \cdot \frac{\partial W}{\partial p})^T \cdot (T(x)-I(W(x,p)))\).
\item Zaktualizuj parametr \(p \leftarrow p+\Delta p\).
\item Powtarzaj kroki od 2 do 7 do czasu, gdy algorytm będzie zbiegał do punktu.
\end{enumerate}

\section{Wybór implementowanego algorytmu}
\label{sec:wyborimplementowanegoalgorytmu}

Dokonując wyboru algorytmu do implementacji w sprzęcie bazowano na gotowych implementacjach w programie \textit{MATLAB}. Algorytmy uruchamiano dla zarejestrowanych sekwencji testowych, takich jak nagrania poruszającego się drona. Warto zwrócić uwagę na fakt, że sekwencje te nagrywane były na jednolitym tle, co zwiększało skuteczność rozwiązań. Stwierdzono, że z zadaniem najlepiej poradził sobie algorytm KLT. Oprócz tego postanowiono zaimplementować prosty algorytm śledzenia przez detekcję do celów testowych.  Z użyciem tego algorytmu badano pozycjonowanie serwomechanizmów w trakcie testowania i doboru nastaw regulatora. Został również przetestowany gotowy algorytm Mean-shift, aby sprawdzić jego działanie w platformie sprzętowej oraz ocenić działanie posiadanej implementacji.